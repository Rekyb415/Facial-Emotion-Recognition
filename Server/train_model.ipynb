{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Necessary constant values are being fixed\n",
    "IMAGE_SIZE = 48\n",
    "ANNOTATION = [\n",
    "    \"neutral\",\n",
    "    \"happiness\",\n",
    "    \"surprise\",\n",
    "    \"sadness\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"contempt\",\n",
    "    \"unknown\",\n",
    "    \"NF\",\n",
    "]\n",
    "MAIN_DIR = \"FER+\"\n",
    "\n",
    "\n",
    "# Loading of fer and fer-plus data in pandas dataframe\n",
    "df_fer_plus = pd.read_csv(os.path.join(MAIN_DIR, \"main_data_csv/fer2013new.csv\"))\n",
    "df_fer = pd.read_csv(os.path.join(MAIN_DIR, \"main_data_csv/fer2013.csv\"))\n",
    "\n",
    "\n",
    "def string_to_image(image_string):\n",
    "    \"\"\"\n",
    "    Take image string as an input and\n",
    "    return an image object as an output.\n",
    "    \"\"\"\n",
    "    image_array = image_string.split(\" \")\n",
    "    image_array = np.asarray(image_array, dtype=np.uint8).reshape(\n",
    "        IMAGE_SIZE, IMAGE_SIZE\n",
    "    )\n",
    "    return Image.fromarray(image_array)\n",
    "\n",
    "\n",
    "# Creating destination folder if it's not exist already\n",
    "WRITE_DATA_PATH = os.path.join(MAIN_DIR, \"emotion_data\")\n",
    "if not os.path.exists(path=WRITE_DATA_PATH):\n",
    "    os.mkdir(path=WRITE_DATA_PATH)\n",
    "\n",
    "os.chdir(path=WRITE_DATA_PATH)\n",
    "for folder_name in ANNOTATION:\n",
    "    if not os.path.exists(path=folder_name):\n",
    "        os.mkdir(path=folder_name)\n",
    "\n",
    "\n",
    "# Turning the pixels data into images and\n",
    "# saving the image into specific directory\n",
    "for index_value in range(0, np.shape(df_fer)[0]):\n",
    "    if isinstance(df_fer_plus[\"Image name\"][index_value], float):\n",
    "        continue\n",
    "    image_obj = string_to_image(df_fer[\"pixels\"][index_value])\n",
    "    annotation_list = list(df_fer_plus.loc[index_value, ANNOTATION])\n",
    "    number_index = annotation_list.index(max(annotation_list))\n",
    "    image_obj.save(ANNOTATION[number_index] + \"/\" + \"{}.png\".format(index_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c16b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 22:52:42.796240: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "happiness\n",
      "surprise\n",
      "sadness\n",
      "anger\n",
      "disgust\n",
      "fear\n",
      "contempt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "### loading data\n",
    "labels = {'neutral': 0,\n",
    "          'happiness': 1,\n",
    "          'surprise': 2,\n",
    "          'sadness': 3,\n",
    "          'anger': 4,\n",
    "          'disgust': 5,\n",
    "          'fear': 6,\n",
    "          'contempt': 7}\n",
    "\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    for filename in os.listdir(\"FER+/emotion_data/\" + label):\n",
    "        if (\n",
    "            filename.split(\".\").pop().lower() == \"png\"\n",
    "        ):\n",
    "            img = load_img(\n",
    "                \"FER+/emotion_data/\" + label + \"/\" + filename,\n",
    "                target_size=(48, 48),\n",
    "                color_mode=\"grayscale\",\n",
    "            )\n",
    "            img = img_to_array(img)\n",
    "            img = img / 255.0\n",
    "            x.append(img)\n",
    "            y.append(labels[label])\n",
    "\n",
    "x = np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36578195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df926ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.50980395],\n",
       "         [0.42745098],\n",
       "         [0.3882353 ],\n",
       "         ...,\n",
       "         [0.39215687],\n",
       "         [0.44705883],\n",
       "         [0.56078434]],\n",
       "\n",
       "        [[0.5176471 ],\n",
       "         [0.4745098 ],\n",
       "         [0.45882353],\n",
       "         ...,\n",
       "         [0.41960785],\n",
       "         [0.34901962],\n",
       "         [0.36862746]],\n",
       "\n",
       "        [[0.5647059 ],\n",
       "         [0.49019608],\n",
       "         [0.49411765],\n",
       "         ...,\n",
       "         [0.52156866],\n",
       "         [0.41568628],\n",
       "         [0.34901962]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         ...,\n",
       "         [0.78431374],\n",
       "         [0.8039216 ],\n",
       "         [0.8117647 ]],\n",
       "\n",
       "        [[0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         ...,\n",
       "         [0.7921569 ],\n",
       "         [0.8039216 ],\n",
       "         [0.79607844]],\n",
       "\n",
       "        [[0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         [0.6039216 ],\n",
       "         ...,\n",
       "         [0.78431374],\n",
       "         [0.79607844],\n",
       "         [0.7921569 ]]],\n",
       "\n",
       "\n",
       "       [[[0.5529412 ],\n",
       "         [0.6392157 ],\n",
       "         [0.67058825],\n",
       "         ...,\n",
       "         [0.7058824 ],\n",
       "         [0.7019608 ],\n",
       "         [0.69803923]],\n",
       "\n",
       "        [[0.6117647 ],\n",
       "         [0.65882355],\n",
       "         [0.7019608 ],\n",
       "         ...,\n",
       "         [0.73333335],\n",
       "         [0.7254902 ],\n",
       "         [0.7294118 ]],\n",
       "\n",
       "        [[0.58431375],\n",
       "         [0.64705884],\n",
       "         [0.70980394],\n",
       "         ...,\n",
       "         [0.76862746],\n",
       "         [0.75686276],\n",
       "         [0.7647059 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7882353 ],\n",
       "         [0.84705883],\n",
       "         [0.85490197],\n",
       "         ...,\n",
       "         [0.93333334],\n",
       "         [0.9254902 ],\n",
       "         [0.9254902 ]],\n",
       "\n",
       "        [[0.8       ],\n",
       "         [0.827451  ],\n",
       "         [0.8392157 ],\n",
       "         ...,\n",
       "         [0.92941177],\n",
       "         [0.9254902 ],\n",
       "         [0.92941177]],\n",
       "\n",
       "        [[0.8156863 ],\n",
       "         [0.8235294 ],\n",
       "         [0.8117647 ],\n",
       "         ...,\n",
       "         [0.92941177],\n",
       "         [0.9254902 ],\n",
       "         [0.92941177]]],\n",
       "\n",
       "\n",
       "       [[[0.79607844],\n",
       "         [0.42745098],\n",
       "         [0.44705883],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.41568628],\n",
       "         [0.42352942],\n",
       "         [0.59607846],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        [[0.40784314],\n",
       "         [0.59607846],\n",
       "         [0.6156863 ],\n",
       "         ...,\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.43137255],\n",
       "         [0.34117648],\n",
       "         [0.3254902 ],\n",
       "         ...,\n",
       "         [0.30588236],\n",
       "         [0.3254902 ],\n",
       "         [0.34509805]],\n",
       "\n",
       "        [[0.4627451 ],\n",
       "         [0.36862746],\n",
       "         [0.36078432],\n",
       "         ...,\n",
       "         [0.39607844],\n",
       "         [0.3372549 ],\n",
       "         [0.35686275]],\n",
       "\n",
       "        [[0.4392157 ],\n",
       "         [0.39607844],\n",
       "         [0.4117647 ],\n",
       "         ...,\n",
       "         [0.45882353],\n",
       "         [0.38039216],\n",
       "         [0.34901962]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.03529412],\n",
       "         [0.03921569],\n",
       "         [0.10196079],\n",
       "         ...,\n",
       "         [0.2784314 ],\n",
       "         [0.4392157 ],\n",
       "         [0.73333335]],\n",
       "\n",
       "        [[0.03921569],\n",
       "         [0.03137255],\n",
       "         [0.11764706],\n",
       "         ...,\n",
       "         [0.27058825],\n",
       "         [0.41568628],\n",
       "         [0.70980394]],\n",
       "\n",
       "        [[0.03529412],\n",
       "         [0.02745098],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.26666668],\n",
       "         [0.39215687],\n",
       "         [0.68235296]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.09411765],\n",
       "         [0.09803922],\n",
       "         [0.23921569],\n",
       "         ...,\n",
       "         [0.11764706],\n",
       "         [0.12156863],\n",
       "         [0.1254902 ]],\n",
       "\n",
       "        [[0.09411765],\n",
       "         [0.10196079],\n",
       "         [0.20392157],\n",
       "         ...,\n",
       "         [0.12156863],\n",
       "         [0.12941177],\n",
       "         [0.1254902 ]],\n",
       "\n",
       "        [[0.10196079],\n",
       "         [0.11764706],\n",
       "         [0.16470589],\n",
       "         ...,\n",
       "         [0.11764706],\n",
       "         [0.12941177],\n",
       "         [0.12941177]]],\n",
       "\n",
       "\n",
       "       [[[0.17254902],\n",
       "         [0.22352941],\n",
       "         [0.34901962],\n",
       "         ...,\n",
       "         [0.12156863],\n",
       "         [0.14117648],\n",
       "         [0.14901961]],\n",
       "\n",
       "        [[0.10588235],\n",
       "         [0.1764706 ],\n",
       "         [0.3254902 ],\n",
       "         ...,\n",
       "         [0.16862746],\n",
       "         [0.10588235],\n",
       "         [0.14901961]],\n",
       "\n",
       "        [[0.10588235],\n",
       "         [0.1882353 ],\n",
       "         [0.27450982],\n",
       "         ...,\n",
       "         [0.3254902 ],\n",
       "         [0.07450981],\n",
       "         [0.1254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8039216 ],\n",
       "         [0.8039216 ],\n",
       "         [0.8       ],\n",
       "         ...,\n",
       "         [0.6627451 ],\n",
       "         [0.6666667 ],\n",
       "         [0.6627451 ]],\n",
       "\n",
       "        [[0.8       ],\n",
       "         [0.79607844],\n",
       "         [0.7921569 ],\n",
       "         ...,\n",
       "         [0.6627451 ],\n",
       "         [0.65882355],\n",
       "         [0.654902  ]],\n",
       "\n",
       "        [[0.79607844],\n",
       "         [0.7921569 ],\n",
       "         [0.7882353 ],\n",
       "         ...,\n",
       "         [0.65882355],\n",
       "         [0.6509804 ],\n",
       "         [0.6509804 ]]],\n",
       "\n",
       "\n",
       "       [[[0.21960784],\n",
       "         [0.21960784],\n",
       "         [0.21176471],\n",
       "         ...,\n",
       "         [0.0627451 ],\n",
       "         [0.07058824],\n",
       "         [0.0627451 ]],\n",
       "\n",
       "        [[0.22352941],\n",
       "         [0.22352941],\n",
       "         [0.21568628],\n",
       "         ...,\n",
       "         [0.07058824],\n",
       "         [0.07450981],\n",
       "         [0.06666667]],\n",
       "\n",
       "        [[0.22352941],\n",
       "         [0.22352941],\n",
       "         [0.21568628],\n",
       "         ...,\n",
       "         [0.08627451],\n",
       "         [0.07450981],\n",
       "         [0.07843138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.02352941],\n",
       "         [0.04313726],\n",
       "         [0.04705882],\n",
       "         ...,\n",
       "         [0.2784314 ],\n",
       "         [0.29803923],\n",
       "         [0.10196079]],\n",
       "\n",
       "        [[0.03529412],\n",
       "         [0.04705882],\n",
       "         [0.03921569],\n",
       "         ...,\n",
       "         [0.28235295],\n",
       "         [0.29803923],\n",
       "         [0.10196079]],\n",
       "\n",
       "        [[0.03137255],\n",
       "         [0.01960784],\n",
       "         [0.01176471],\n",
       "         ...,\n",
       "         [0.30588236],\n",
       "         [0.29411766],\n",
       "         [0.07450981]]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78ddca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle= True)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b70b0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,479,240\n",
      "Trainable params: 4,475,272\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BlueItMy03/anaconda3/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "\n",
    "\n",
    "no_of_classes = 8\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))#4th CNN layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766dfa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,SGD,Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"run app/model.h5\", monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='loss',\n",
    "                              factor=0.2,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c69a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.7519 - accuracy: 0.3644\n",
      "Epoch 1: accuracy improved from -inf to 0.36435, saving model to run app/model.h5\n",
      "500/500 [==============================] - 504s 1s/step - loss: 1.7519 - accuracy: 0.3644 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.4613 - accuracy: 0.4820\n",
      "Epoch 2: accuracy improved from 0.36435 to 0.48204, saving model to run app/model.h5\n",
      "500/500 [==============================] - 516s 1s/step - loss: 1.4613 - accuracy: 0.4820 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.3195 - accuracy: 0.5373\n",
      "Epoch 3: accuracy improved from 0.48204 to 0.53727, saving model to run app/model.h5\n",
      "500/500 [==============================] - 494s 989ms/step - loss: 1.3195 - accuracy: 0.5373 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.2200 - accuracy: 0.5724\n",
      "Epoch 4: accuracy improved from 0.53727 to 0.57243, saving model to run app/model.h5\n",
      "500/500 [==============================] - 589s 1s/step - loss: 1.2200 - accuracy: 0.5724 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.1191 - accuracy: 0.6057\n",
      "Epoch 5: accuracy improved from 0.57243 to 0.60572, saving model to run app/model.h5\n",
      "500/500 [==============================] - 562s 1s/step - loss: 1.1191 - accuracy: 0.6057 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 1.0583 - accuracy: 0.6264\n",
      "Epoch 6: accuracy improved from 0.60572 to 0.62641, saving model to run app/model.h5\n",
      "500/500 [==============================] - 582s 1s/step - loss: 1.0583 - accuracy: 0.6264 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9983 - accuracy: 0.6416\n",
      "Epoch 7: accuracy improved from 0.62641 to 0.64160, saving model to run app/model.h5\n",
      "500/500 [==============================] - 679s 1s/step - loss: 0.9983 - accuracy: 0.6416 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9459 - accuracy: 0.6640\n",
      "Epoch 8: accuracy improved from 0.64160 to 0.66398, saving model to run app/model.h5\n",
      "500/500 [==============================] - 654s 1s/step - loss: 0.9459 - accuracy: 0.6640 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.9034 - accuracy: 0.6744\n",
      "Epoch 9: accuracy improved from 0.66398 to 0.67441, saving model to run app/model.h5\n",
      "500/500 [==============================] - 624s 1s/step - loss: 0.9034 - accuracy: 0.6744 - lr: 1.0000e-04\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8732 - accuracy: 0.6847\n",
      "Epoch 10: accuracy improved from 0.67441 to 0.68468, saving model to run app/model.h5\n",
      "500/500 [==============================] - 673s 1s/step - loss: 0.8732 - accuracy: 0.6847 - lr: 1.0000e-04\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8367 - accuracy: 0.6972\n",
      "Epoch 11: accuracy improved from 0.68468 to 0.69724, saving model to run app/model.h5\n",
      "500/500 [==============================] - 737s 1s/step - loss: 0.8367 - accuracy: 0.6972 - lr: 1.0000e-04\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.8042 - accuracy: 0.7095\n",
      "Epoch 12: accuracy improved from 0.69724 to 0.70951, saving model to run app/model.h5\n",
      "500/500 [==============================] - 678s 1s/step - loss: 0.8042 - accuracy: 0.7095 - lr: 1.0000e-04\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7772 - accuracy: 0.7181\n",
      "Epoch 13: accuracy improved from 0.70951 to 0.71809, saving model to run app/model.h5\n",
      "500/500 [==============================] - 654s 1s/step - loss: 0.7772 - accuracy: 0.7181 - lr: 1.0000e-04\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7524 - accuracy: 0.7295\n",
      "Epoch 14: accuracy improved from 0.71809 to 0.72948, saving model to run app/model.h5\n",
      "500/500 [==============================] - 615s 1s/step - loss: 0.7524 - accuracy: 0.7295 - lr: 1.0000e-04\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.7418\n",
      "Epoch 15: accuracy improved from 0.72948 to 0.74179, saving model to run app/model.h5\n",
      "500/500 [==============================] - 594s 1s/step - loss: 0.7239 - accuracy: 0.7418 - lr: 1.0000e-04\n",
      "111/111 [==============================] - 19s 164ms/step - loss: 0.6788 - accuracy: 0.7563\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=15, batch_size=64, callbacks=callbacks_list)\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "##print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
